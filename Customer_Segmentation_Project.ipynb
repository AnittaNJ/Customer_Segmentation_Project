{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Business Context**\n",
        "You are provided an e-commerce data set from a real-world organisation to perform customer segmentation with clustering models to improve marketing efforts (SAS, 2024). It is a transnational data set with customers from five continents (Oceania, North America, Europe, Africa, and Asia) and 47 countries.\n",
        "\n",
        "The data set contains 951,668 rows, each representing a product a customer ordered. The data set contains details about the customer (e.g. location, product type, loyalty member) and order (e.g. days to delivery, delivery date, order date, cost, quantity ordered, profit) based on orders between 1 January 2012 and 30 December 2016.\n",
        "\n",
        "Your task is to develop a robust customer segmentation to assist the e-commerce company in understanding and serving its customers better. This will help to have a more customer-centric focus, improving marketing efficiency. Therefore, you’ll explore the data, employ preprocessing and feature engineering, dimension reduction, and perform customer segmentation with clustering models.\n",
        "\n",
        "\n",
        "## **Objective**\n",
        "Apply statistical and ML methods to perform customer segmentation with clustering techniques."
      ],
      "metadata": {
        "id": "O7iPqVqG7TEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "import scipy.cluster.hierarchy as sch\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "TTAIqsSEGfrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gdown"
      ],
      "metadata": {
        "id": "mn1_spG2sdfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown ''"
      ],
      "metadata": {
        "id": "DQAwxOsxCUth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('CUSTOMERS_CLEAN.csv')"
      ],
      "metadata": {
        "id": "WH_eedLb6YQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory data analysis"
      ],
      "metadata": {
        "id": "q3hGPg2j5z0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "HQhlO0ev_u4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "-YJPKN5o-6Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include='object')"
      ],
      "metadata": {
        "id": "LxaWDb3QZQtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "Tt-GF2LW_wP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "RpBdF9M7SzI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing 21 duplicates in dataframe\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "fk_xQC9WTfrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for null\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "tPkHcGI7SmWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing null values\n",
        "df = df.fillna('')\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "FxjGLm3R-BLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['Customer ID'].unique())"
      ],
      "metadata": {
        "id": "KPWWcDFZ-Io6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming the data to standardise and for efficient programming\n",
        "df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%d%b%Y')\n",
        "df['Delivery_Date'] = pd.to_datetime(df['Delivery_Date'], format='%d%b%Y')\n",
        "df['Customer_BirthDate'] = pd.to_datetime(df['Customer_BirthDate'], format='%d%b%Y')\n",
        "df['Total Revenue'] = df['Total Revenue'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "df['Discount']=df['Discount'].replace('[\\%]', '', regex=True).replace('   .','0').astype(int)\n",
        "df['Profit'] = df['Profit'].replace('[\\(\\)\\$,]', '', regex=True).astype(float)\n",
        "df['Unit Cost'] = df['Unit Cost'].replace('[\\$,]', '', regex=True).astype(float)"
      ],
      "metadata": {
        "id": "u4wDDba1b7U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the status of features after transformations\n",
        "df.info()"
      ],
      "metadata": {
        "id": "m9YLsiPrh7Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the numerical columns are filtered and assigned to dataframe\n",
        "num_df = df[['Quantity','Total Revenue','Unit Cost','Discount','Profit','Days to Delivery','Loyalty Num']].copy()\n",
        "num_df"
      ],
      "metadata": {
        "id": "-TGWJGM7YiKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualising numerical columns in boxplots to identify extreme values\n",
        "plt.figure(figsize=(18, 10))\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.boxplot(df['Quantity'])\n",
        "plt.title('Box Plot of Quantity')\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.boxplot(df['Total Revenue'])\n",
        "plt.title('Box Plot of Total Revenue')\n",
        "\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.boxplot(df['Unit Cost'])\n",
        "plt.title('Box Plot of Unit Cost')\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.boxplot(df['Discount'])\n",
        "plt.title('Box Plot of Discount')\n",
        "\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.boxplot(df['Profit'])\n",
        "plt.title('Box Plot of Profit')\n",
        "\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.boxplot(df['Days to Delivery'])\n",
        "plt.title('Box Plot of Days to Delivery')\n",
        "\n",
        "plt.subplot(3, 3, 7)\n",
        "plt.boxplot(df['Loyalty Num'])\n",
        "plt.title('Box Plot of Loyalty Num')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KOdzkA7nqLiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting outliers using IQR"
      ],
      "metadata": {
        "id": "X7qI7TOvcYG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_df = num_df.copy()\n",
        "for col in outlier_df.columns:\n",
        "\n",
        "  Q1 = outlier_df[col].quantile(0.25)\n",
        "  Q3 = outlier_df[col].quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "\n",
        "  outlier_df[f'Outlier_{col}'] = ((outlier_df[col] < (Q1 - 1.5 * IQR)) | (outlier_df[col] > (Q3 + 1.5 * IQR))).astype(int)\n",
        "\n",
        "outlier_df"
      ],
      "metadata": {
        "id": "bn5ub45H004z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "RyGOlHbJCDuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new features for frequency, recency, CLV, average unit cost, and customer age"
      ],
      "metadata": {
        "id": "h4bITCyxeJaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Frequency'] = df.groupby('Customer ID')['Order ID'].transform('count')\n",
        "df['Frequency']"
      ],
      "metadata": {
        "id": "0x3awbvdkXt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Recency'] = (pd.to_datetime('today') - df['Delivery_Date']).dt.days\n",
        "df['Recency']"
      ],
      "metadata": {
        "id": "sVxfRjdiIvC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CLV'] = df.groupby('Customer ID')['Total Revenue'].transform('sum')\n",
        "df['CLV']"
      ],
      "metadata": {
        "id": "7-59CoZFrbxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Avg_UnitCost'] = df.groupby('Customer ID')['Unit Cost'].transform('mean')\n",
        "df['Avg_UnitCost']"
      ],
      "metadata": {
        "id": "TnPuIT92ZVa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = pd.Timestamp('now')\n",
        "df['customer_age'] = (today - df['Customer_BirthDate']).dt.days // 365\n",
        "df['customer_age']"
      ],
      "metadata": {
        "id": "6mzliTXJadOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transformations"
      ],
      "metadata": {
        "id": "vNejIUNGec8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregation operations and groupy() function was used to get one customer per row.\n",
        "agg_operations = {\n",
        "    'Frequency':'max',\n",
        "    'Recency':'min',\n",
        "    'CLV':'max',\n",
        "    'customer_age':'max',\n",
        "    'Avg_UnitCost':'mean'\n",
        "}\n",
        "\n",
        "df = df.groupby('Customer ID').agg(agg_operations).reset_index()\n",
        "df_aggr = df[['Frequency','Recency','CLV','customer_age','Avg_UnitCost']]"
      ],
      "metadata": {
        "id": "4lwhAuocdbyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering"
      ],
      "metadata": {
        "id": "t845yLQbe6mW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more efficient programming, incorporated the pipeline method to use column transformers and k-means clustering."
      ],
      "metadata": {
        "id": "gRYJsenEeqnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "  transformers=[('num', StandardScaler(), ['Frequency','Recency','CLV','customer_age','Avg_UnitCost'])]\n",
        ")"
      ],
      "metadata": {
        "id": "FVOyPncOWgR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=10, n_init=10)\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('kmeans', kmeans)])\n",
        "pipeline.fit(df_aggr)"
      ],
      "metadata": {
        "id": "LGuV_75BWgFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting preprocessed data from pipeline"
      ],
      "metadata": {
        "id": "0QY0L60ufC6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessed = pipeline.named_steps['preprocessor'].transform(df_aggr)"
      ],
      "metadata": {
        "id": "umSXRsKiZXWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction using PCA"
      ],
      "metadata": {
        "id": "Tg0EZUu8eszh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca_df = pd.DataFrame(pca.fit_transform(df_preprocessed), columns=['pca_1', 'pca_2'])"
      ],
      "metadata": {
        "id": "OZHWndRsZZ42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elbow method"
      ],
      "metadata": {
        "id": "EhU3G6xkfL8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wcss = []\n",
        "\n",
        "for k in range(2, 16):\n",
        "  pipeline.named_steps['kmeans'].set_params(n_clusters=k)\n",
        "  pipeline.fit(df_aggr)\n",
        "  wcss.append(pipeline.named_steps['kmeans'].inertia_)"
      ],
      "metadata": {
        "id": "El9wrSxDZZL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(wcss, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.xticks(range(0, len(wcss)), range(2, len(wcss) + 2))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PjoPylWAZY-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette analysis"
      ],
      "metadata": {
        "id": "g4rwk3y3fT9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_avgs = []\n",
        "fig, axes = plt.subplots(5, 2, figsize=(16, 24))\n",
        "fig.suptitle(\"KMeans Clustering Analysis\", fontsize=14, fontweight='bold')\n",
        "\n",
        "for k in range(2, 7):\n",
        "  ax1, ax2 = axes[k-2]\n",
        "  pipeline.named_steps['kmeans'].set_params(n_clusters=k)\n",
        "  pipeline.fit(df_aggr)\n",
        "\n",
        "  labels = pipeline.named_steps['kmeans'].labels_\n",
        "  silhouette_avg = silhouette_score(df_preprocessed, labels)\n",
        "  silhouette_avgs.append(silhouette_avg)\n",
        "  sample_silhouette_values = silhouette_samples(df_preprocessed, labels)\n",
        "\n",
        "  y_lower = 10\n",
        "  for i in range(k):\n",
        "    ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
        "    ith_cluster_silhouette_values.sort()\n",
        "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "\n",
        "    color = cm.nipy_spectral(float(i) / k)\n",
        "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
        "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "  ax1.set_title(f\"The silhouette plot for the various clusters (n_clusters = {k}).\")\n",
        "  ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "  ax1.set_ylabel(\"Cluster label\")\n",
        "  ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "  ax1.set_yticks([])\n",
        "  ax1.set_xticks(np.arange(-0.1, 1.1, 0.2))\n",
        "\n",
        "  colors = cm.nipy_spectral(labels.astype(float) / k)\n",
        "  ax2.scatter(pca_df['pca_1'], pca_df['pca_2'], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')\n",
        "  centers = pca.transform(pipeline.named_steps['kmeans'].cluster_centers_)\n",
        "  ax2.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "  for i, c in enumerate(centers):\n",
        "    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')\n",
        "  ax2.set_title(\"The visualization of the clustered data.\")\n",
        "  ax2.set_xlabel(\"Feature space for the 1st PCA component\")\n",
        "  ax2.set_ylabel(\"Feature space for the 2nd PCA component\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Xee0NuAa4Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(silhouette_avgs, marker='o')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Average Silhouette Score')\n",
        "plt.xticks(range(0, len(silhouette_avgs)), range(2, len(silhouette_avgs) + 2))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-KAH5Sxea-Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from the above visualisation we found out the best K as 5\n",
        "k=5\n",
        "pipeline.named_steps['kmeans'].set_params(n_clusters=k)\n",
        "pipeline.fit(df_aggr)\n",
        "labels = pipeline.named_steps['kmeans'].labels_\n",
        "labels"
      ],
      "metadata": {
        "id": "Q5Bv4PL9c54o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'] = labels\n",
        "df"
      ],
      "metadata": {
        "id": "3DA41r1eeK0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA for visualisation"
      ],
      "metadata": {
        "id": "bLW5tlWofu3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_df['cluster'] = labels\n",
        "pca_df"
      ],
      "metadata": {
        "id": "bD5fxThswlw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(\n",
        "  x='pca_1',\n",
        "  y='pca_2',\n",
        "  hue='cluster',\n",
        "  data=pca_df,\n",
        "  palette='Set1',\n",
        "  marker='.',\n",
        "  s=30,\n",
        "  linewidth=0,\n",
        "  alpha=0.7\n",
        ")\n",
        "centers = pca.transform(pipeline.named_steps['kmeans'].cluster_centers_)\n",
        "sns.scatterplot(x=centers[:, 0], y=centers[:, 1], color=\"white\", alpha=1, s=200, edgecolor='k', legend=False)\n",
        "for i, c in enumerate(centers):\n",
        "  plt.scatter(x=c[0], y=c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')\n",
        "plt.title('PCA Plot with Cluster Labels')\n",
        "plt.xlabel(\"Feature space for the 1st PCA component\")\n",
        "plt.ylabel(\"Feature space for the 2nd PCA component\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9asJGwrNe8EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "t-SNE for visualisation"
      ],
      "metadata": {
        "id": "Ip-obCRsg5GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_result = tsne.fit_transform(df_preprocessed)\n",
        "df_tsne = pd.DataFrame(data=tsne_result, columns=['t-SNE1', 't-SNE2'])\n"
      ],
      "metadata": {
        "id": "K6lLiQf9epyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tsne['cluster'] = labels\n",
        "df_tsne"
      ],
      "metadata": {
        "id": "CPSSwVrYlH-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "  x='t-SNE1',\n",
        "  y='t-SNE2',\n",
        "  hue='cluster',\n",
        "  data=df_tsne,\n",
        "  palette='Set1',\n",
        "  marker='.',\n",
        "  s=30,\n",
        "  linewidth=0,\n",
        "  alpha=0.7\n",
        ")\n",
        "plt.title('t-SNE Visualization of Clusters')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fe4D9X12omRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoxPlot Visualisation (Features Vs Clusters)"
      ],
      "metadata": {
        "id": "okq9iUkcpjwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df_aggr[['Frequency','Recency','CLV','customer_age','Avg_UnitCost']]:\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  sns.boxplot(\n",
        "    x='cluster',\n",
        "    y=column,\n",
        "    data=df,\n",
        "    hue='cluster',\n",
        "    legend=False,\n",
        "    palette='Set1'\n",
        "  )\n",
        "  plt.title(f'Boxplot of {column} by Cluster')\n",
        "  plt.xlabel('Cluster')\n",
        "  plt.ylabel(column)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "WRiyvFFwqG57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agglomerative Clustering"
      ],
      "metadata": {
        "id": "CulYMmikWZzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the notebook was crashing due to huge amout of data, data sampled to 10000 rows to fix the issue."
      ],
      "metadata": {
        "id": "CD0Rc4hkhl8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_df = df_aggr.sample(n= 10000).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "jlm5UHP86n49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agglo_cluster = AgglomerativeClustering(n_clusters=3, metric='euclidean', linkage='average')\n",
        "small_df['cluster'] = agglo_cluster.fit_predict(small_df)\n",
        "small_df"
      ],
      "metadata": {
        "id": "L3d8dzk45xOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = linkage(small_df, method='average')\n",
        "plt.figure(figsize=(15, 10))\n",
        "dendrogram(Z)\n",
        "plt.title('Dendrogram for Customer Data')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bry_ygPG8ABf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> The objective was to develop a robust customer segmentation to assist the e-commerce company in understanding and serving its customers better. The dataset had 20 features to choose on which features or feature combinations can help in customer segmentation. The steps followed are exploratory data analysis, data preprocessing, feature engineering and determining the best number of clusters(k) using the Elbow and Silhouette score methods and based on optimum number of ‘k’, performing the k-means clustering. The resulting clusters can then be visualised in 2D by reducing the dimensions using PCA and t-SNE models.\n"
      ],
      "metadata": {
        "id": "yjrtAugN6rBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference:\n",
        "SAS, 2024. CUSTOMERS_CLEAN [Data set]. SAS. Last revised on 15 December 2021. [Accessed 20 February 2024]."
      ],
      "metadata": {
        "id": "ggnYxWfMMvuj"
      }
    }
  ]
}